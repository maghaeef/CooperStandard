{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammad/.local/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "2025-03-09 04:30:26.991049: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-03-09 04:30:26.991123: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting training data for balancing...\n",
      "Fixed time series length from training data: 280\n",
      "Total number of batches: 6837\n",
      "Number of low batches (t5 < 3.5): 2277\n",
      "Number of normal batches (3.5 <= t5 <= 5.0): 2280\n",
      "Number of high batches (t5 > 5.0): 2280\n",
      "\n",
      "Total number of batches: 695\n",
      "Number of low batches (t5 < 3.5): 162\n",
      "Number of normal batches (3.5 <= t5 <= 5.0): 493\n",
      "Number of high batches (t5 > 5.0): 40\n",
      "\n",
      "Total number of batches: 695\n",
      "Number of low batches (t5 < 3.5): 162\n",
      "Number of normal batches (3.5 <= t5 <= 5.0): 506\n",
      "Number of high batches (t5 > 5.0): 27\n",
      "\n",
      "Number of training data points: 6837\n",
      "Number of validation data points: 695\n",
      "Number of test data points: 695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-09 04:32:48.011697: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2025-03-09 04:32:48.011727: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2025-03-09 04:32:48.011755: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ubuntu): /proc/driver/nvidia/version does not exist\n",
      "2025-03-09 04:32:48.012078: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "214/214 [==============================] - 42s 181ms/step - loss: 2.1247 - mae: 1.1396 - val_loss: 0.5117 - val_mae: 0.5603\n",
      "Epoch 2/50\n",
      "214/214 [==============================] - 38s 178ms/step - loss: 0.9789 - mae: 0.8553 - val_loss: 0.4010 - val_mae: 0.4900\n",
      "Epoch 3/50\n",
      "214/214 [==============================] - 37s 173ms/step - loss: 0.7268 - mae: 0.7222 - val_loss: 0.2878 - val_mae: 0.4038\n",
      "Epoch 4/50\n",
      "214/214 [==============================] - 37s 173ms/step - loss: 0.4854 - mae: 0.5572 - val_loss: 0.2735 - val_mae: 0.3873\n",
      "Epoch 5/50\n",
      "214/214 [==============================] - 37s 173ms/step - loss: 0.3905 - mae: 0.4709 - val_loss: 0.2896 - val_mae: 0.4003\n",
      "Epoch 6/50\n",
      "214/214 [==============================] - 42s 196ms/step - loss: 0.3404 - mae: 0.4310 - val_loss: 0.2594 - val_mae: 0.3740\n",
      "Epoch 7/50\n",
      "214/214 [==============================] - 43s 199ms/step - loss: 0.3012 - mae: 0.4000 - val_loss: 0.2350 - val_mae: 0.3574\n",
      "Epoch 8/50\n",
      "214/214 [==============================] - 43s 202ms/step - loss: 0.2757 - mae: 0.3809 - val_loss: 0.2268 - val_mae: 0.3477\n",
      "Epoch 9/50\n",
      "214/214 [==============================] - 43s 199ms/step - loss: 0.2522 - mae: 0.3621 - val_loss: 0.2268 - val_mae: 0.3499\n",
      "Epoch 10/50\n",
      "214/214 [==============================] - 43s 201ms/step - loss: 0.2262 - mae: 0.3386 - val_loss: 0.1953 - val_mae: 0.3243\n",
      "Epoch 11/50\n",
      "214/214 [==============================] - 40s 188ms/step - loss: 0.2080 - mae: 0.3207 - val_loss: 0.1738 - val_mae: 0.3022\n",
      "Epoch 12/50\n",
      "214/214 [==============================] - 37s 175ms/step - loss: 0.1924 - mae: 0.3058 - val_loss: 0.1795 - val_mae: 0.3148\n",
      "Epoch 13/50\n",
      "214/214 [==============================] - 37s 174ms/step - loss: 0.1799 - mae: 0.2936 - val_loss: 0.1556 - val_mae: 0.2837\n",
      "Epoch 14/50\n",
      "214/214 [==============================] - 42s 195ms/step - loss: 0.1678 - mae: 0.2816 - val_loss: 0.1455 - val_mae: 0.2743\n",
      "Epoch 15/50\n",
      "214/214 [==============================] - 44s 204ms/step - loss: 0.1557 - mae: 0.2666 - val_loss: 0.1389 - val_mae: 0.2667\n",
      "Epoch 16/50\n",
      "214/214 [==============================] - 43s 201ms/step - loss: 0.1503 - mae: 0.2628 - val_loss: 0.1380 - val_mae: 0.2656\n",
      "Epoch 17/50\n",
      "214/214 [==============================] - 43s 202ms/step - loss: 0.1433 - mae: 0.2537 - val_loss: 0.1319 - val_mae: 0.2583\n",
      "Epoch 18/50\n",
      "214/214 [==============================] - 44s 204ms/step - loss: 0.1382 - mae: 0.2470 - val_loss: 0.1226 - val_mae: 0.2480\n",
      "Epoch 19/50\n",
      "214/214 [==============================] - 41s 189ms/step - loss: 0.1380 - mae: 0.2485 - val_loss: 0.1254 - val_mae: 0.2502\n",
      "Epoch 20/50\n",
      "214/214 [==============================] - 37s 175ms/step - loss: 0.1337 - mae: 0.2426 - val_loss: 0.1252 - val_mae: 0.2524\n",
      "Epoch 21/50\n",
      "214/214 [==============================] - 43s 199ms/step - loss: 0.1300 - mae: 0.2375 - val_loss: 0.1211 - val_mae: 0.2463\n",
      "Epoch 22/50\n",
      "214/214 [==============================] - 42s 199ms/step - loss: 0.1314 - mae: 0.2389 - val_loss: 0.1238 - val_mae: 0.2488\n",
      "Epoch 23/50\n",
      "214/214 [==============================] - 44s 204ms/step - loss: 0.1272 - mae: 0.2333 - val_loss: 0.1285 - val_mae: 0.2537\n",
      "Epoch 24/50\n",
      "214/214 [==============================] - 43s 200ms/step - loss: 0.1267 - mae: 0.2336 - val_loss: 0.1332 - val_mae: 0.2598\n",
      "Epoch 25/50\n",
      "214/214 [==============================] - 41s 191ms/step - loss: 0.1264 - mae: 0.2325 - val_loss: 0.1189 - val_mae: 0.2423\n",
      "Epoch 26/50\n",
      "214/214 [==============================] - 39s 180ms/step - loss: 0.1250 - mae: 0.2303 - val_loss: 0.1259 - val_mae: 0.2541\n",
      "Epoch 27/50\n",
      "214/214 [==============================] - 37s 175ms/step - loss: 0.1255 - mae: 0.2324 - val_loss: 0.1235 - val_mae: 0.2472\n",
      "Epoch 28/50\n",
      "214/214 [==============================] - 43s 203ms/step - loss: 0.1271 - mae: 0.2353 - val_loss: 0.1238 - val_mae: 0.2476\n",
      "Epoch 29/50\n",
      "214/214 [==============================] - 44s 206ms/step - loss: 0.1233 - mae: 0.2302 - val_loss: 0.1247 - val_mae: 0.2490\n",
      "Epoch 30/50\n",
      "214/214 [==============================] - 45s 208ms/step - loss: 0.1241 - mae: 0.2302 - val_loss: 0.1519 - val_mae: 0.2844\n",
      "Epoch 31/50\n",
      "214/214 [==============================] - 44s 205ms/step - loss: 0.1245 - mae: 0.2316 - val_loss: 0.1209 - val_mae: 0.2469\n",
      "Epoch 32/50\n",
      "214/214 [==============================] - 44s 204ms/step - loss: 0.1267 - mae: 0.2344 - val_loss: 0.1225 - val_mae: 0.2474\n",
      "Epoch 33/50\n",
      "214/214 [==============================] - 44s 205ms/step - loss: 0.1206 - mae: 0.2248 - val_loss: 0.1265 - val_mae: 0.2512\n",
      "Epoch 34/50\n",
      "214/214 [==============================] - 44s 204ms/step - loss: 0.1238 - mae: 0.2302 - val_loss: 0.1258 - val_mae: 0.2496\n",
      "Epoch 35/50\n",
      "214/214 [==============================] - 40s 185ms/step - loss: 0.1216 - mae: 0.2290 - val_loss: 0.1260 - val_mae: 0.2532\n",
      "Epoch 36/50\n",
      "214/214 [==============================] - 43s 201ms/step - loss: 0.1231 - mae: 0.2307 - val_loss: 0.1300 - val_mae: 0.2568\n",
      "Epoch 37/50\n",
      "214/214 [==============================] - 43s 201ms/step - loss: 0.1211 - mae: 0.2280 - val_loss: 0.1170 - val_mae: 0.2399\n",
      "Epoch 38/50\n",
      "214/214 [==============================] - 43s 202ms/step - loss: 0.1200 - mae: 0.2258 - val_loss: 0.1161 - val_mae: 0.2386\n",
      "Epoch 39/50\n",
      "214/214 [==============================] - 43s 203ms/step - loss: 0.1229 - mae: 0.2306 - val_loss: 0.1198 - val_mae: 0.2450\n",
      "Epoch 40/50\n",
      "214/214 [==============================] - 43s 203ms/step - loss: 0.1220 - mae: 0.2277 - val_loss: 0.1228 - val_mae: 0.2494\n",
      "Epoch 41/50\n",
      "214/214 [==============================] - 43s 202ms/step - loss: 0.1193 - mae: 0.2261 - val_loss: 0.1208 - val_mae: 0.2455\n",
      "Epoch 42/50\n",
      "214/214 [==============================] - 43s 201ms/step - loss: 0.1195 - mae: 0.2249 - val_loss: 0.1219 - val_mae: 0.2466\n",
      "Epoch 43/50\n",
      "214/214 [==============================] - 43s 202ms/step - loss: 0.1206 - mae: 0.2273 - val_loss: 0.1185 - val_mae: 0.2421\n",
      "Epoch 44/50\n",
      "214/214 [==============================] - 43s 201ms/step - loss: 0.1202 - mae: 0.2274 - val_loss: 0.1199 - val_mae: 0.2437\n",
      "Epoch 45/50\n",
      "214/214 [==============================] - 43s 200ms/step - loss: 0.1196 - mae: 0.2264 - val_loss: 0.1182 - val_mae: 0.2415\n",
      "Epoch 46/50\n",
      "214/214 [==============================] - 43s 200ms/step - loss: 0.1184 - mae: 0.2252 - val_loss: 0.1211 - val_mae: 0.2454\n",
      "Epoch 47/50\n",
      "214/214 [==============================] - 43s 200ms/step - loss: 0.1191 - mae: 0.2280 - val_loss: 0.1207 - val_mae: 0.2455\n",
      "Epoch 48/50\n",
      "214/214 [==============================] - 42s 198ms/step - loss: 0.1170 - mae: 0.2229 - val_loss: 0.1199 - val_mae: 0.2442\n",
      "Epoch 49/50\n",
      "214/214 [==============================] - 43s 199ms/step - loss: 0.1196 - mae: 0.2267 - val_loss: 0.1196 - val_mae: 0.2448\n",
      "Epoch 50/50\n",
      "214/214 [==============================] - 43s 201ms/step - loss: 0.1186 - mae: 0.2248 - val_loss: 0.1236 - val_mae: 0.2500\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set - Loss (MSE): 0.1176, MAE: 0.2227\n",
      "Validation Set - Loss (MSE): 0.1236, MAE: 0.2500\n",
      "Test Set - Loss (MSE): 0.1805, MAE: 0.2477\n",
      "--- Training Set ---\n",
      "Low: MAE = 0.2233, Accuracy = 85.02%\n",
      "Normal: MAE = 0.2546, Accuracy = 84.17%\n",
      "High: MAE = 0.1902, Accuracy = 93.99%\n",
      "--- Validation Set ---\n",
      "Low: MAE = 0.2382, Accuracy = 80.86%\n",
      "Normal: MAE = 0.2584, Accuracy = 82.76%\n",
      "High: MAE = 0.1937, Accuracy = 85.00%\n",
      "--- Test Set ---\n",
      "Low: MAE = 0.2677, Accuracy = 80.25%\n",
      "Normal: MAE = 0.2382, Accuracy = 84.98%\n",
      "High: MAE = 0.3061, Accuracy = 85.19%\n",
      "Class Distribution for Training Set:\n",
      "normal    2280\n",
      "high      2280\n",
      "low       2277\n",
      "dtype: int64\n",
      "Percentage:\n",
      "normal    33.347960\n",
      "high      33.347960\n",
      "low       33.304081\n",
      "dtype: float64\n",
      "\n",
      "Class Distribution for Validation Set:\n",
      "normal    493\n",
      "low       162\n",
      "high       40\n",
      "dtype: int64\n",
      "Percentage:\n",
      "normal    70.935252\n",
      "low       23.309353\n",
      "high       5.755396\n",
      "dtype: float64\n",
      "\n",
      "Class Distribution for Test Set:\n",
      "normal    506\n",
      "low       162\n",
      "high       27\n",
      "dtype: int64\n",
      "Percentage:\n",
      "normal    72.805755\n",
      "low       23.309353\n",
      "high       3.884892\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bounds import bounds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ast\n",
    "import pandas as pd\n",
    "from cooper_standard import CooperStandard\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Concatenate\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ============================================================\n",
    "# Configuration flag: Set to True to augment training data,\n",
    "# or False to use the original training data.\n",
    "USE_AUGMENTATION = True\n",
    "# ============================================================\n",
    "\n",
    "# %% Setup and Data Loading\n",
    "file_path = \"DataOn2025Jan08.xlsx\"\n",
    "sheet_names = [\"NES2060C05Line2\", \"NES2060C06Line2\"]\n",
    "variables = [\n",
    "    \"batch_number\", \"MDRTorqueS1\", \"MDRTorqueS2\", \n",
    "    \"mh\", \"ml\", \"TimeAtML\", \"TimeAtML_min\", \"ml_min\",\n",
    "    \"start_time\", \"end_time\", \"t5\"\n",
    "]\n",
    "\n",
    "# Instantiate the CooperStandard class and load data\n",
    "cooper_standard = CooperStandard(file_path, sheet_names, variables)\n",
    "df_all = cooper_standard.load_data()\n",
    "cleaned_df, removed_batches = cooper_standard.preprocessing(280)\n",
    "\n",
    "# Set lower and upper bounds for t5 (from your bounds dictionary)\n",
    "lb, ub = bounds[\"2060C05\"][0], bounds[\"2060C05\"][1]\n",
    "\n",
    "# %% Split the Original DataFrame into Training, Validation, and Test Sets\n",
    "# (We do this before augmentation so that only the training data gets augmented.)\n",
    "train_df, temp_df = train_test_split(cleaned_df, train_size=0.7, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, train_size=0.5, random_state=42)\n",
    "\n",
    "if USE_AUGMENTATION:\n",
    "    print(\"Augmenting training data for balancing...\")\n",
    "    # Augment only the training set using the SMOTE-like method.\n",
    "    train_df = cooper_standard.balance_data_with_synthetic(train_df, lb, ub, k=5)\n",
    "else:\n",
    "    print(\"Using original training data without augmentation.\")\n",
    "\n",
    "# %% Convert DataFrames to Dictionary Format (before normalization)\n",
    "# train_dict = cooper_standard.convert_to_dict(train_df)\n",
    "# val_dict = cooper_standard.convert_to_dict(val_df)\n",
    "# test_dict = cooper_standard.convert_to_dict(test_df)\n",
    "# Convert the training set to dictionary and determine the fixed length from training data.\n",
    "train_dict = cooper_standard.convert_to_dict(train_df)\n",
    "# Assume training set is non-empty; get fixed_length from one training sample.\n",
    "fixed_length = list(train_dict.values())[0][\"time_series\"].shape[0]\n",
    "print(\"Fixed time series length from training data:\", fixed_length)\n",
    "\n",
    "# Convert validation and test sets using the fixed_length.\n",
    "val_dict = cooper_standard.convert_to_dict(val_df, fixed_length=fixed_length)\n",
    "test_dict = cooper_standard.convert_to_dict(test_df, fixed_length=fixed_length)\n",
    "\n",
    "\n",
    "# %% Normalize the Data Using Training Statistics\n",
    "# (Normalization is applied after augmentation.)\n",
    "train_dict_norm = cooper_standard.normalize_data(train_dict, fit=True)\n",
    "val_dict_norm = cooper_standard.normalize_data(val_dict, fit=False)\n",
    "test_dict_norm = cooper_standard.normalize_data(test_dict, fit=False)\n",
    "\n",
    "# Print t5 categories for each split to verify balancing\n",
    "cooper_standard.print_t5_categories(train_dict_norm, lb, ub)\n",
    "cooper_standard.print_t5_categories(val_dict_norm, lb, ub)\n",
    "cooper_standard.print_t5_categories(test_dict_norm, lb, ub)\n",
    "\n",
    "print(f\"Number of training data points: {len(train_dict_norm)}\")\n",
    "print(f\"Number of validation data points: {len(val_dict_norm)}\")\n",
    "print(f\"Number of test data points: {len(test_dict_norm)}\")\n",
    "\n",
    "# %% Prepare Data for Model Training\n",
    "def prepare_data_from_dict(data_dict):\n",
    "    # Extract time series, scalar features, and targets from the dictionary\n",
    "    time_series = np.array([batch[\"time_series\"] for batch in data_dict.values()])\n",
    "    scalar_features = np.array([batch[\"scalar_features\"] for batch in data_dict.values()])\n",
    "    targets = np.array([batch[\"t5\"] for batch in data_dict.values()])\n",
    "    return time_series, scalar_features, targets\n",
    "\n",
    "train_ts, train_scalar, train_targets = prepare_data_from_dict(train_dict_norm)\n",
    "val_ts, val_scalar, val_targets = prepare_data_from_dict(val_dict_norm)\n",
    "test_ts, test_scalar, test_targets = prepare_data_from_dict(test_dict_norm)\n",
    "\n",
    "# %% Build the Neural Network Model\n",
    "sequence_length = train_ts.shape[1]  # e.g., number of time steps (280)\n",
    "num_scalar_features = train_scalar.shape[1]  # e.g., 6 scalar features\n",
    "\n",
    "# Time series branch (using LSTM)\n",
    "ts_input = Input(shape=(sequence_length, 4), name='time_series_input')\n",
    "lstm_out = LSTM(units=64)(ts_input)\n",
    "\n",
    "# Scalar features branch (using Dense layer)\n",
    "scalar_input = Input(shape=(num_scalar_features,), name='scalar_input')\n",
    "scalar_dense = Dense(16, activation='relu')(scalar_input)\n",
    "\n",
    "# Combine both branches\n",
    "combined = Concatenate()([lstm_out, scalar_dense])\n",
    "dense = Dense(32, activation='relu')(combined)\n",
    "output = Dense(1, name='t5_output')(dense)  # Regression output for t5\n",
    "\n",
    "model = Model(inputs=[ts_input, scalar_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# %% Train the Model\n",
    "history = model.fit(\n",
    "    [train_ts, train_scalar], train_targets,\n",
    "    validation_data=([val_ts, val_scalar], val_targets),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# %% Plot Training and Validation Loss\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# %% Evaluate the Model on All Sets\n",
    "train_loss, train_mae = model.evaluate([train_ts, train_scalar], train_targets, verbose=0)\n",
    "print(f\"Training Set - Loss (MSE): {train_loss:.4f}, MAE: {train_mae:.4f}\")\n",
    "val_loss, val_mae = model.evaluate([val_ts, val_scalar], val_targets, verbose=0)\n",
    "print(f\"Validation Set - Loss (MSE): {val_loss:.4f}, MAE: {val_mae:.4f}\")\n",
    "test_loss, test_mae = model.evaluate([test_ts, test_scalar], test_targets, verbose=0)\n",
    "print(f\"Test Set - Loss (MSE): {test_loss:.4f}, MAE: {test_mae:.4f}\")\n",
    "\n",
    "# %% Make Predictions\n",
    "train_pred = model.predict([train_ts, train_scalar]).flatten()\n",
    "val_pred = model.predict([val_ts, val_scalar]).flatten()\n",
    "test_pred = model.predict([test_ts, test_scalar]).flatten()\n",
    "\n",
    "# %% Compute and Print Class Metrics\n",
    "def compute_class_metrics(true_t5, pred_t5, lb, ub):\n",
    "    # Define masks for each t5 region\n",
    "    low_mask = true_t5 < lb\n",
    "    normal_mask = (true_t5 >= lb) & (true_t5 <= ub)\n",
    "    high_mask = true_t5 > ub\n",
    "    \n",
    "    def get_metrics(mask, pred_condition):\n",
    "        if np.sum(mask) == 0:\n",
    "            return np.nan, np.nan\n",
    "        mae = np.mean(np.abs(true_t5[mask] - pred_t5[mask]))\n",
    "        accuracy = np.mean(pred_condition[mask]) * 100  # simple placeholder metric\n",
    "        return mae, accuracy\n",
    "\n",
    "    low_mae, low_acc = get_metrics(low_mask, pred_t5 < lb)\n",
    "    normal_mae, normal_acc = get_metrics(normal_mask, (pred_t5 >= lb) & (pred_t5 <= ub))\n",
    "    high_mae, high_acc = get_metrics(high_mask, pred_t5 > ub)\n",
    "    \n",
    "    return {\n",
    "        'low': {'mae': low_mae, 'accuracy': low_acc},\n",
    "        'normal': {'mae': normal_mae, 'accuracy': normal_acc},\n",
    "        'high': {'mae': high_mae, 'accuracy': high_acc}\n",
    "    }\n",
    "\n",
    "def print_metrics(metrics, dataset_name):\n",
    "    print(f\"--- {dataset_name} ---\")\n",
    "    for cls in ['low', 'normal', 'high']:\n",
    "        mae = metrics[cls]['mae']\n",
    "        acc = metrics[cls]['accuracy']\n",
    "        if np.isnan(mae):\n",
    "            print(f\"{cls.capitalize()}: No data points\")\n",
    "        else:\n",
    "            print(f\"{cls.capitalize()}: MAE = {mae:.4f}, Accuracy = {acc:.2f}%\")\n",
    "\n",
    "train_metrics = compute_class_metrics(train_targets, train_pred, lb, ub)\n",
    "val_metrics = compute_class_metrics(val_targets, val_pred, lb, ub)\n",
    "test_metrics = compute_class_metrics(test_targets, test_pred, lb, ub)\n",
    "\n",
    "print_metrics(train_metrics, \"Training Set\")\n",
    "print_metrics(val_metrics, \"Validation Set\")\n",
    "print_metrics(test_metrics, \"Test Set\")\n",
    "\n",
    "# %% Additional Analysis: Class Distribution\n",
    "def categorize_t5(t5):\n",
    "    if t5 < lb:\n",
    "        return 'low'\n",
    "    elif lb <= t5 <= ub:\n",
    "        return 'normal'\n",
    "    else:\n",
    "        return 'high'\n",
    "\n",
    "def analyze_class_distribution(targets, dataset_name):\n",
    "    classes = [categorize_t5(t) for t in targets]\n",
    "    class_counts = pd.Series(classes).value_counts()\n",
    "    print(f\"Class Distribution for {dataset_name}:\")\n",
    "    print(class_counts)\n",
    "    print(f\"Percentage:\\n{class_counts / len(targets) * 100}\\n\")\n",
    "\n",
    "analyze_class_distribution(train_targets, \"Training Set\")\n",
    "analyze_class_distribution(val_targets, \"Validation Set\")\n",
    "analyze_class_distribution(test_targets, \"Test Set\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
