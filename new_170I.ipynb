{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammad/.local/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "2025-03-09 05:13:43.835964: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-03-09 05:13:43.836088: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting training data for balancing...\n",
      "Fixed time series length from training data: 280\n",
      "Total number of batches: 10151\n",
      "Number of low batches (t5 < 5.5): 3384\n",
      "Number of normal batches (5.5 <= t5 <= 9.5): 3383\n",
      "Number of high batches (t5 > 9.5): 3384\n",
      "\n",
      "Total number of batches: 737\n",
      "Number of low batches (t5 < 5.5): 9\n",
      "Number of normal batches (5.5 <= t5 <= 9.5): 726\n",
      "Number of high batches (t5 > 9.5): 2\n",
      "\n",
      "Total number of batches: 738\n",
      "Number of low batches (t5 < 5.5): 9\n",
      "Number of normal batches (5.5 <= t5 <= 9.5): 726\n",
      "Number of high batches (t5 > 9.5): 3\n",
      "\n",
      "Number of training data points: 10151\n",
      "Number of validation data points: 737\n",
      "Number of test data points: 738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-09 05:17:02.803623: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2025-03-09 05:17:02.803690: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2025-03-09 05:17:02.803738: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ubuntu): /proc/driver/nvidia/version does not exist\n",
      "2025-03-09 05:17:02.804255: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-09 05:17:05.964025: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 45476480 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "318/318 [==============================] - 68s 201ms/step - loss: 11.1082 - mae: 2.5090 - val_loss: 0.6992 - val_mae: 0.6741\n",
      "Epoch 2/50\n",
      "318/318 [==============================] - 53s 167ms/step - loss: 1.5898 - mae: 1.0037 - val_loss: 0.8696 - val_mae: 0.7014\n",
      "Epoch 3/50\n",
      "318/318 [==============================] - 55s 174ms/step - loss: 0.9586 - mae: 0.7543 - val_loss: 0.9490 - val_mae: 0.7372\n",
      "Epoch 4/50\n",
      "318/318 [==============================] - 63s 199ms/step - loss: 0.8944 - mae: 0.7269 - val_loss: 0.9376 - val_mae: 0.7361\n",
      "Epoch 5/50\n",
      "318/318 [==============================] - 63s 199ms/step - loss: 0.8475 - mae: 0.7037 - val_loss: 0.9777 - val_mae: 0.7540\n",
      "Epoch 6/50\n",
      "318/318 [==============================] - 64s 202ms/step - loss: 0.8142 - mae: 0.6908 - val_loss: 0.9503 - val_mae: 0.7432\n",
      "Epoch 7/50\n",
      "318/318 [==============================] - 64s 200ms/step - loss: 0.8016 - mae: 0.6902 - val_loss: 0.9603 - val_mae: 0.7657\n",
      "Epoch 8/50\n",
      "318/318 [==============================] - 62s 196ms/step - loss: 0.7813 - mae: 0.6829 - val_loss: 0.8550 - val_mae: 0.7169\n",
      "Epoch 9/50\n",
      "318/318 [==============================] - 60s 189ms/step - loss: 0.7712 - mae: 0.6802 - val_loss: 0.9376 - val_mae: 0.7518\n",
      "Epoch 10/50\n",
      "318/318 [==============================] - 63s 200ms/step - loss: 0.7556 - mae: 0.6722 - val_loss: 0.9577 - val_mae: 0.7588\n",
      "Epoch 11/50\n",
      "318/318 [==============================] - 57s 180ms/step - loss: 0.7561 - mae: 0.6723 - val_loss: 0.9088 - val_mae: 0.7413\n",
      "Epoch 12/50\n",
      "318/318 [==============================] - 55s 173ms/step - loss: 0.7336 - mae: 0.6652 - val_loss: 0.9568 - val_mae: 0.7633\n",
      "Epoch 13/50\n",
      "318/318 [==============================] - 61s 193ms/step - loss: 0.7260 - mae: 0.6599 - val_loss: 0.8350 - val_mae: 0.7100\n",
      "Epoch 14/50\n",
      "318/318 [==============================] - 62s 196ms/step - loss: 0.7211 - mae: 0.6598 - val_loss: 0.9385 - val_mae: 0.7569\n",
      "Epoch 15/50\n",
      "318/318 [==============================] - 63s 199ms/step - loss: 0.7148 - mae: 0.6574 - val_loss: 0.9151 - val_mae: 0.7472\n",
      "Epoch 16/50\n",
      "318/318 [==============================] - 62s 195ms/step - loss: 0.7071 - mae: 0.6556 - val_loss: 0.9430 - val_mae: 0.7709\n",
      "Epoch 17/50\n",
      "318/318 [==============================] - 63s 197ms/step - loss: 0.7034 - mae: 0.6514 - val_loss: 0.9176 - val_mae: 0.7456\n",
      "Epoch 18/50\n",
      "318/318 [==============================] - 63s 198ms/step - loss: 0.6905 - mae: 0.6439 - val_loss: 0.9420 - val_mae: 0.7535\n",
      "Epoch 19/50\n",
      "318/318 [==============================] - 62s 195ms/step - loss: 0.6864 - mae: 0.6441 - val_loss: 0.9303 - val_mae: 0.7585\n",
      "Epoch 20/50\n",
      "318/318 [==============================] - 63s 197ms/step - loss: 0.6900 - mae: 0.6460 - val_loss: 0.9735 - val_mae: 0.7661\n",
      "Epoch 21/50\n",
      "318/318 [==============================] - 54s 170ms/step - loss: 0.6771 - mae: 0.6384 - val_loss: 0.9637 - val_mae: 0.7823\n",
      "Epoch 22/50\n",
      "318/318 [==============================] - 57s 179ms/step - loss: 0.6657 - mae: 0.6327 - val_loss: 0.9222 - val_mae: 0.7463\n",
      "Epoch 23/50\n",
      "318/318 [==============================] - 57s 179ms/step - loss: 0.6560 - mae: 0.6283 - val_loss: 0.9321 - val_mae: 0.7614\n",
      "Epoch 24/50\n",
      "318/318 [==============================] - 56s 177ms/step - loss: 0.6530 - mae: 0.6269 - val_loss: 0.9620 - val_mae: 0.7896\n",
      "Epoch 25/50\n",
      "318/318 [==============================] - 56s 176ms/step - loss: 0.6521 - mae: 0.6272 - val_loss: 0.9890 - val_mae: 0.7797\n",
      "Epoch 26/50\n",
      "318/318 [==============================] - 55s 174ms/step - loss: 0.6392 - mae: 0.6203 - val_loss: 0.9963 - val_mae: 0.7764\n",
      "Epoch 27/50\n",
      "318/318 [==============================] - 56s 175ms/step - loss: 0.6312 - mae: 0.6145 - val_loss: 0.9493 - val_mae: 0.7729\n",
      "Epoch 28/50\n",
      "318/318 [==============================] - 56s 175ms/step - loss: 0.6309 - mae: 0.6153 - val_loss: 1.0086 - val_mae: 0.8011\n",
      "Epoch 29/50\n",
      "318/318 [==============================] - 55s 174ms/step - loss: 0.6201 - mae: 0.6089 - val_loss: 0.9511 - val_mae: 0.7612\n",
      "Epoch 30/50\n",
      "318/318 [==============================] - 56s 175ms/step - loss: 0.6038 - mae: 0.6001 - val_loss: 0.9423 - val_mae: 0.7713\n",
      "Epoch 31/50\n",
      "318/318 [==============================] - 56s 175ms/step - loss: 0.6003 - mae: 0.5980 - val_loss: 0.8887 - val_mae: 0.7420\n",
      "Epoch 32/50\n",
      "318/318 [==============================] - 56s 175ms/step - loss: 0.5965 - mae: 0.5965 - val_loss: 0.8820 - val_mae: 0.7316\n",
      "Epoch 33/50\n",
      "318/318 [==============================] - 55s 174ms/step - loss: 0.5901 - mae: 0.5936 - val_loss: 0.9125 - val_mae: 0.7441\n",
      "Epoch 34/50\n",
      "318/318 [==============================] - 56s 176ms/step - loss: 0.5837 - mae: 0.5900 - val_loss: 1.0549 - val_mae: 0.7952\n",
      "Epoch 35/50\n",
      "318/318 [==============================] - 55s 174ms/step - loss: 0.5796 - mae: 0.5861 - val_loss: 1.0494 - val_mae: 0.8031\n",
      "Epoch 36/50\n",
      "318/318 [==============================] - 55s 174ms/step - loss: 0.5608 - mae: 0.5742 - val_loss: 0.9811 - val_mae: 0.7766\n",
      "Epoch 37/50\n",
      "318/318 [==============================] - 56s 176ms/step - loss: 0.5525 - mae: 0.5693 - val_loss: 1.0055 - val_mae: 0.8005\n",
      "Epoch 38/50\n",
      "318/318 [==============================] - 56s 176ms/step - loss: 0.5504 - mae: 0.5678 - val_loss: 0.9294 - val_mae: 0.7604\n",
      "Epoch 39/50\n",
      "318/318 [==============================] - 55s 174ms/step - loss: 0.5418 - mae: 0.5616 - val_loss: 0.9438 - val_mae: 0.7564\n",
      "Epoch 40/50\n",
      "318/318 [==============================] - 56s 175ms/step - loss: 0.5330 - mae: 0.5551 - val_loss: 0.9685 - val_mae: 0.7727\n",
      "Epoch 41/50\n",
      "318/318 [==============================] - 56s 175ms/step - loss: 0.5277 - mae: 0.5534 - val_loss: 0.9664 - val_mae: 0.7769\n",
      "Epoch 42/50\n",
      "318/318 [==============================] - 55s 174ms/step - loss: 0.5130 - mae: 0.5437 - val_loss: 0.9531 - val_mae: 0.7589\n",
      "Epoch 43/50\n",
      "318/318 [==============================] - 56s 175ms/step - loss: 0.5121 - mae: 0.5416 - val_loss: 0.9852 - val_mae: 0.7823\n",
      "Epoch 44/50\n",
      "318/318 [==============================] - 56s 175ms/step - loss: 0.4995 - mae: 0.5348 - val_loss: 1.0749 - val_mae: 0.8159\n",
      "Epoch 45/50\n",
      "318/318 [==============================] - 55s 174ms/step - loss: 0.4970 - mae: 0.5313 - val_loss: 0.8477 - val_mae: 0.7190\n",
      "Epoch 46/50\n",
      "318/318 [==============================] - 56s 175ms/step - loss: 0.4908 - mae: 0.5283 - val_loss: 0.8359 - val_mae: 0.7039\n",
      "Epoch 47/50\n",
      "318/318 [==============================] - 56s 175ms/step - loss: 0.4908 - mae: 0.5284 - val_loss: 1.0439 - val_mae: 0.7915\n",
      "Epoch 48/50\n",
      "318/318 [==============================] - 56s 175ms/step - loss: 0.4799 - mae: 0.5202 - val_loss: 0.9858 - val_mae: 0.7740\n",
      "Epoch 49/50\n",
      "318/318 [==============================] - 55s 174ms/step - loss: 0.4779 - mae: 0.5176 - val_loss: 0.9228 - val_mae: 0.7477\n",
      "Epoch 50/50\n",
      "318/318 [==============================] - 56s 176ms/step - loss: 0.4722 - mae: 0.5144 - val_loss: 0.9456 - val_mae: 0.7462\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-09 06:05:23.758837: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 45476480 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set - Loss (MSE): 0.4949, MAE: 0.5373\n",
      "Validation Set - Loss (MSE): 0.9456, MAE: 0.7462\n",
      "Test Set - Loss (MSE): 0.8807, MAE: 0.7209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-09 06:05:42.091847: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 45476480 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Set ---\n",
      "Low: MAE = 0.3550, Accuracy = 80.88%\n",
      "Normal: MAE = 0.7262, Accuracy = 94.09%\n",
      "High: MAE = 0.5309, Accuracy = 52.39%\n",
      "--- Validation Set ---\n",
      "Low: MAE = 0.4465, Accuracy = 55.56%\n",
      "Normal: MAE = 0.7503, Accuracy = 92.70%\n",
      "High: MAE = 0.6093, Accuracy = 50.00%\n",
      "--- Test Set ---\n",
      "Low: MAE = 1.1669, Accuracy = 44.44%\n",
      "Normal: MAE = 0.7133, Accuracy = 92.15%\n",
      "High: MAE = 1.2233, Accuracy = 33.33%\n",
      "Class Distribution for Training Set:\n",
      "high      3384\n",
      "low       3384\n",
      "normal    3383\n",
      "dtype: int64\n",
      "Percentage:\n",
      "high      33.336617\n",
      "low       33.336617\n",
      "normal    33.326766\n",
      "dtype: float64\n",
      "\n",
      "Class Distribution for Validation Set:\n",
      "normal    726\n",
      "low         9\n",
      "high        2\n",
      "dtype: int64\n",
      "Percentage:\n",
      "normal    98.507463\n",
      "low        1.221167\n",
      "high       0.271370\n",
      "dtype: float64\n",
      "\n",
      "Class Distribution for Test Set:\n",
      "normal    726\n",
      "low         9\n",
      "high        3\n",
      "dtype: int64\n",
      "Percentage:\n",
      "normal    98.373984\n",
      "low        1.219512\n",
      "high       0.406504\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bounds import bounds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ast\n",
    "import pandas as pd\n",
    "from cooper_standard import CooperStandard\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Concatenate\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ============================================================\n",
    "# Configuration flag: Set to True to augment training data,\n",
    "# or False to use the original training data.\n",
    "USE_AUGMENTATION = True\n",
    "# ============================================================\n",
    "\n",
    "# %% Setup and Data Loading\n",
    "file_path = \"DataOn2025Jan08.xlsx\"\n",
    "sheet_names = [\"NES170I08Line1\"]\n",
    "variables = [\n",
    "    \"batch_number\", \"MDRTorqueS1\", \"MDRTorqueS2\", \n",
    "    \"mh\", \"ml\", \"TimeAtML\", \"TimeAtML_min\", \"ml_min\",\n",
    "    \"start_time\", \"end_time\", \"t5\"\n",
    "]\n",
    "\n",
    "# Instantiate the CooperStandard class and load data\n",
    "cooper_standard = CooperStandard(file_path, sheet_names, variables)\n",
    "df_all = cooper_standard.load_data()\n",
    "cleaned_df, removed_batches = cooper_standard.preprocessing(280)\n",
    "\n",
    "# Set lower and upper bounds for t5 (from your bounds dictionary)\n",
    "lb, ub = bounds[\"170I\"][0], bounds[\"170I\"][1]\n",
    "\n",
    "# %% Split the Original DataFrame into Training, Validation, and Test Sets\n",
    "# (We do this before augmentation so that only the training data gets augmented.)\n",
    "train_df, temp_df = train_test_split(cleaned_df, train_size=0.7, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, train_size=0.5, random_state=42)\n",
    "\n",
    "if USE_AUGMENTATION:\n",
    "    print(\"Augmenting training data for balancing...\")\n",
    "    # Augment only the training set using the SMOTE-like method.\n",
    "    train_df = cooper_standard.balance_data_with_synthetic(train_df, lb, ub, k=5)\n",
    "else:\n",
    "    print(\"Using original training data without augmentation.\")\n",
    "\n",
    "# Convert the training set to dictionary and determine the fixed length from training data.\n",
    "train_dict = cooper_standard.convert_to_dict(train_df)\n",
    "# Assume training set is non-empty; get fixed_length from one training sample.\n",
    "fixed_length = list(train_dict.values())[0][\"time_series\"].shape[0]\n",
    "print(\"Fixed time series length from training data:\", fixed_length)\n",
    "\n",
    "# Convert validation and test sets using the fixed_length.\n",
    "val_dict = cooper_standard.convert_to_dict(val_df, fixed_length=fixed_length)\n",
    "test_dict = cooper_standard.convert_to_dict(test_df, fixed_length=fixed_length)\n",
    "\n",
    "# %% Normalize the Data Using Training Statistics\n",
    "# (Normalization is applied after augmentation.)\n",
    "train_dict_norm = cooper_standard.normalize_data(train_dict, fit=True)\n",
    "val_dict_norm = cooper_standard.normalize_data(val_dict, fit=False)\n",
    "test_dict_norm = cooper_standard.normalize_data(test_dict, fit=False)\n",
    "\n",
    "# Print t5 categories for each split to verify balancing\n",
    "cooper_standard.print_t5_categories(train_dict_norm, lb, ub)\n",
    "cooper_standard.print_t5_categories(val_dict_norm, lb, ub)\n",
    "cooper_standard.print_t5_categories(test_dict_norm, lb, ub)\n",
    "\n",
    "print(f\"Number of training data points: {len(train_dict_norm)}\")\n",
    "print(f\"Number of validation data points: {len(val_dict_norm)}\")\n",
    "print(f\"Number of test data points: {len(test_dict_norm)}\")\n",
    "\n",
    "# %% Prepare Data for Model Training\n",
    "def prepare_data_from_dict(data_dict):\n",
    "    # Extract time series, scalar features, and targets from the dictionary\n",
    "    time_series = np.array([batch[\"time_series\"] for batch in data_dict.values()])\n",
    "    scalar_features = np.array([batch[\"scalar_features\"] for batch in data_dict.values()])\n",
    "    targets = np.array([batch[\"t5\"] for batch in data_dict.values()])\n",
    "    return time_series, scalar_features, targets\n",
    "\n",
    "train_ts, train_scalar, train_targets = prepare_data_from_dict(train_dict_norm)\n",
    "val_ts, val_scalar, val_targets = prepare_data_from_dict(val_dict_norm)\n",
    "test_ts, test_scalar, test_targets = prepare_data_from_dict(test_dict_norm)\n",
    "\n",
    "# %% Build the Neural Network Model\n",
    "sequence_length = train_ts.shape[1]  # e.g., number of time steps (280)\n",
    "num_scalar_features = train_scalar.shape[1]  # e.g., 6 scalar features\n",
    "\n",
    "# Time series branch (using LSTM)\n",
    "ts_input = Input(shape=(sequence_length, 4), name='time_series_input')\n",
    "lstm_out = LSTM(units=64)(ts_input)\n",
    "\n",
    "# Scalar features branch (using Dense layer)\n",
    "scalar_input = Input(shape=(num_scalar_features,), name='scalar_input')\n",
    "scalar_dense = Dense(16, activation='relu')(scalar_input)\n",
    "\n",
    "# Combine both branches\n",
    "combined = Concatenate()([lstm_out, scalar_dense])\n",
    "dense = Dense(32, activation='relu')(combined)\n",
    "output = Dense(1, name='t5_output')(dense)  # Regression output for t5\n",
    "\n",
    "model = Model(inputs=[ts_input, scalar_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# %% Train the Model\n",
    "history = model.fit(\n",
    "    [train_ts, train_scalar], train_targets,\n",
    "    validation_data=([val_ts, val_scalar], val_targets),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# %% Plot Training and Validation Loss\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# %% Evaluate the Model on All Sets\n",
    "train_loss, train_mae = model.evaluate([train_ts, train_scalar], train_targets, verbose=0)\n",
    "print(f\"Training Set - Loss (MSE): {train_loss:.4f}, MAE: {train_mae:.4f}\")\n",
    "val_loss, val_mae = model.evaluate([val_ts, val_scalar], val_targets, verbose=0)\n",
    "print(f\"Validation Set - Loss (MSE): {val_loss:.4f}, MAE: {val_mae:.4f}\")\n",
    "test_loss, test_mae = model.evaluate([test_ts, test_scalar], test_targets, verbose=0)\n",
    "print(f\"Test Set - Loss (MSE): {test_loss:.4f}, MAE: {test_mae:.4f}\")\n",
    "\n",
    "# %% Make Predictions\n",
    "train_pred = model.predict([train_ts, train_scalar]).flatten()\n",
    "val_pred = model.predict([val_ts, val_scalar]).flatten()\n",
    "test_pred = model.predict([test_ts, test_scalar]).flatten()\n",
    "\n",
    "# %% Compute and Print Class Metrics\n",
    "def compute_class_metrics(true_t5, pred_t5, lb, ub):\n",
    "    # Define masks for each t5 region\n",
    "    low_mask = true_t5 < lb\n",
    "    normal_mask = (true_t5 >= lb) & (true_t5 <= ub)\n",
    "    high_mask = true_t5 > ub\n",
    "    \n",
    "    def get_metrics(mask, pred_condition):\n",
    "        if np.sum(mask) == 0:\n",
    "            return np.nan, np.nan\n",
    "        mae = np.mean(np.abs(true_t5[mask] - pred_t5[mask]))\n",
    "        accuracy = np.mean(pred_condition[mask]) * 100  # simple placeholder metric\n",
    "        return mae, accuracy\n",
    "\n",
    "    low_mae, low_acc = get_metrics(low_mask, pred_t5 < lb)\n",
    "    normal_mae, normal_acc = get_metrics(normal_mask, (pred_t5 >= lb) & (pred_t5 <= ub))\n",
    "    high_mae, high_acc = get_metrics(high_mask, pred_t5 > ub)\n",
    "    \n",
    "    return {\n",
    "        'low': {'mae': low_mae, 'accuracy': low_acc},\n",
    "        'normal': {'mae': normal_mae, 'accuracy': normal_acc},\n",
    "        'high': {'mae': high_mae, 'accuracy': high_acc}\n",
    "    }\n",
    "\n",
    "def print_metrics(metrics, dataset_name):\n",
    "    print(f\"--- {dataset_name} ---\")\n",
    "    for cls in ['low', 'normal', 'high']:\n",
    "        mae = metrics[cls]['mae']\n",
    "        acc = metrics[cls]['accuracy']\n",
    "        if np.isnan(mae):\n",
    "            print(f\"{cls.capitalize()}: No data points\")\n",
    "        else:\n",
    "            print(f\"{cls.capitalize()}: MAE = {mae:.4f}, Accuracy = {acc:.2f}%\")\n",
    "\n",
    "train_metrics = compute_class_metrics(train_targets, train_pred, lb, ub)\n",
    "val_metrics = compute_class_metrics(val_targets, val_pred, lb, ub)\n",
    "test_metrics = compute_class_metrics(test_targets, test_pred, lb, ub)\n",
    "\n",
    "print_metrics(train_metrics, \"Training Set\")\n",
    "print_metrics(val_metrics, \"Validation Set\")\n",
    "print_metrics(test_metrics, \"Test Set\")\n",
    "\n",
    "# %% Additional Analysis: Class Distribution\n",
    "def categorize_t5(t5):\n",
    "    if t5 < lb:\n",
    "        return 'low'\n",
    "    elif lb <= t5 <= ub:\n",
    "        return 'normal'\n",
    "    else:\n",
    "        return 'high'\n",
    "\n",
    "def analyze_class_distribution(targets, dataset_name):\n",
    "    classes = [categorize_t5(t) for t in targets]\n",
    "    class_counts = pd.Series(classes).value_counts()\n",
    "    print(f\"Class Distribution for {dataset_name}:\")\n",
    "    print(class_counts)\n",
    "    print(f\"Percentage:\\n{class_counts / len(targets) * 100}\\n\")\n",
    "\n",
    "analyze_class_distribution(train_targets, \"Training Set\")\n",
    "analyze_class_distribution(val_targets, \"Validation Set\")\n",
    "analyze_class_distribution(test_targets, \"Test Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
